---
title: "Intermediate SQL for Data Scientists"
author: "George Melrose"
date: "05/07/2024"
output:
   html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
rm(list = ls())

knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(readr,tidyverse, data.table,DBI,odbc,RSQLite,plotly,dygraphs,xts,
               reticulate)


options(max.print = 1000) 
getOption("max.print")

con <- dbConnect(SQLite(), dbname = ":memory:")
knitr::opts_chunk$set(connection = "con")
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)


# List the tables present in the database connected through 'con'
tables <- dbListTables(con)

# Print the list of tables
print(tables)
```

```{r reading in data to the pretend database, warning=FALSE, message=FALSE, include=FALSE}
# List of table names (should match the original table names)
tables <- c("author","book_author","book_language","country",
            "customer","customer","customer_address","order_line",
            "order_status","publisher","shipping_method","address","address_status") # Replace with your actual table names

book <- read_csv("book.csv")

book$publication_date <- as.character(book$publication_date)
  
# Write the table to the new SQL connection
dbWriteTable(con, "book", book, overwrite = TRUE)

cust_order <- read_csv("cust_order.csv")

cust_order$order_date <- as.character(cust_order$order_date)
  
# Write the table to the new SQL connection
dbWriteTable(con, "cust_order", cust_order, overwrite = TRUE)
  

order_history <- read_csv("order_history.csv")

order_history$status_date <- as.character(order_history$status_date)
  
# Write the table to the new SQL connection
dbWriteTable(con, "order_history", order_history, overwrite = TRUE)
  
  

# Loop through each table and read it from the CSV file
for (table in tables) {
  # Read the table from the CSV file
  data <- read_csv(paste0(table, ".csv"))
  
  # Write the table to the new SQL connection
  dbWriteTable(con, table, data, overwrite = TRUE)
}



rm(data)

```

```{r gravity bookstore dataset erd png, message=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/gam55/Downloads/gravity_bookstore_erd.png")

```

```{sql looking at the book table columns}

select * from book

```

```{sql looking at the book_language table columns}
select * from book_language
```

```{r Print the tables currently in the database, warning=FALSE, message=FALSE, include=FALSE}
# List the tables present in the database connected through 'con'
tables <- dbListTables(con)

# Print the list of tables
print(tables)
```

```{sql list all the tables from the database, include=FALSE}
SELECT name FROM sqlite_master WHERE type='table';
```

## 1 - Indexes & Views {.tabset .tabset-fade .tabset-pills}

This section and the following take inspiration but not much content, from the LinkedIn learning course ***"Intermediate SQL for Data Scientists"*** - <https://www.linkedin.com/learning/intermediate-sql-for-data-scientists>

```{r gravity bookstore dataset erd png repeated}
knitr::include_graphics("C:/Users/gam55/Downloads/gravity_bookstore_erd.png")

```

### Indexes

Indexes in SQLite are structures designed to improve the speed of data retrieval. They're similar to indexes in a book, allowing for faster access to rows in a table based on the values of one or more columns.

Types of Indexes -

1.  ***Single-Column Index*** - Created on a single column.

2.  ***Multi-Column Index*** - Created on two or more columns.

3.  ***Unique Index*** - Ensures that all values in the indexed column(s) are unique.

4.  ***Primary Key Index*** - Automatically created when a table has a primary key constraint.

5.  ***Automatic Indexes*** - Sometimes SQLite creates indexes automatically to optimize query performance, particularly for joins.

```{sql creating a single column index}

CREATE INDEX Customer_IDs ON cust_order(customer_id); 


```

```{sql creating a multi column index}

CREATE INDEX Customer_Orders ON cust_order(order_id, customer_id);

```

CREATE UNIQUE INDEX unique_countries ON country(country_name);

This SQL code above fails - A unique index does not discard non-unique values or automatically filter out duplicates. Instead, it enforces a constraint that prevents duplicates from being inserted into the table in the first place.

```{sql creating a unique index}

CREATE UNIQUE INDEX unique_status_ids ON order_status(status_id);

```

List all indexes associated with a table -

```{sql looking at all indexes associated with cust_order}
PRAGMA index_list(cust_order);
```

Get information about a specific index -

```{sql getting information about the customer_orders index specifically}

PRAGMA index_info(Customer_Orders);

```

Indexes can be dropped using the DROP INDEX statement -

```{sql removing the Cusomter_Order index}

DROP INDEX Customer_Orders;

```

Checking the index deletion has worked -

```{sql checking index deletion has worked}
PRAGMA index_list(cust_order);
```

An example with a more complex and intricate query -

```{sql looking at the book table}

select * from book

```

```{sql looking at author names}

select author_name from author where author_name == "Walter Scott"

```

Creating an index of author names.

```{sql creating an index of author names}

CREATE INDEX Author_names ON author(author_name);

```

Now our 'server' should use that index to optimise the performance of this query.

```{sql filtering Galaxy bokstore data for 1997 to 2000 publications by JK Rowling and Bill Bryson}

SELECT
    b.title,
    b.isbn13,
    b.num_pages,
    b.publication_date,
    a.author_name,
    ol.price
FROM book b
INNER JOIN book_author ba ON b.book_id = ba.book_id
INNER JOIN author a ON ba.author_id = a.author_id
INNER JOIN order_line ol ON b.book_id = ol.book_id
INNER JOIN cust_order co ON ol.order_id = co.order_id
WHERE a.author_name IN ('J.K. Rowling', 'Bill Bryson')
  AND strftime('%Y', b.publication_date) IN ('1997','1998', '1999','2000')
ORDER BY ol.price DESC;


```

### Views

Views in SQLite are virtual tables that provide a way to represent the results of a query as a table.

Reasons to use Views -

1.  **Simplify Complex Queries** - By encapsulating complex joins and calculations within a view, queries can be simpler and more understandable.

2.  **Enhance Security** - Views can restrict access to specific data by exposing only certain columns or rows to users.

3.  **Provide Abstraction** - Offer a layer of abstraction, allowing changes in the underlying database schema without affecting the end users.

4.  **Improve Maintainability** - Views centralise query logic, making the system easier to maintain and modify.

```{sql creating a view of all of Bill Brysons books}
CREATE VIEW Bryson_Books AS
SELECT
    b.title,
    b.isbn13,
    b.num_pages,
    b.publication_date,
    a.author_name,
    ol.price
FROM book b
INNER JOIN book_author ba ON b.book_id = ba.book_id
INNER JOIN author a ON ba.author_id = a.author_id
INNER JOIN order_line ol ON b.book_id = ol.book_id
INNER JOIN cust_order co ON ol.order_id = co.order_id
WHERE a.author_name IN ('Bill Bryson');


```

```{sql creating a view of all of JK Rowling books}
CREATE VIEW Rowling_Books AS
SELECT
    b.title,
    b.isbn13,
    b.num_pages,
    b.publication_date,
    a.author_name,
    ol.price
FROM book b
INNER JOIN book_author ba ON b.book_id = ba.book_id
INNER JOIN author a ON ba.author_id = a.author_id
INNER JOIN order_line ol ON b.book_id = ol.book_id
INNER JOIN cust_order co ON ol.order_id = co.order_id
WHERE a.author_name IN ('J.K. Rowling');


```

```{sql creating a view of all of Walter Scotts books}
CREATE VIEW Walter_Scott_Books AS
SELECT
    b.title,
    b.isbn13,
    b.num_pages,
    b.publication_date,
    a.author_name,
    ol.price
FROM book b
INNER JOIN book_author ba ON b.book_id = ba.book_id
INNER JOIN author a ON ba.author_id = a.author_id
INNER JOIN order_line ol ON b.book_id = ol.book_id
INNER JOIN cust_order co ON ol.order_id = co.order_id
WHERE a.author_name IN ('Walter Scott');


```

```{sql looking at all the columns and rows from the Bryson Books view}
SELECT * FROM Bryson_Books;
```

```{sql looking at all the columns and rows from the Walter Scott Books view}
SELECT * FROM Walter_Scott_Books;
```

Views themselves are not directly updatable, but they can be dropped and recreated -

```{sql dropping the Bryson books view}
DROP VIEW IF EXISTS Bryson_Books;
```

```{sql checking what views are present}
SELECT name FROM sqlite_master WHERE type='view';
```

```{sql seeing the definition of the Walter Scott view}
SELECT sql FROM sqlite_master WHERE type='view' AND name='Walter_Scott_Books';
```

------------------------------------------------------------------------

## 2 - Statistical aggregate functions {.tabset .tabset-fade .tabset-pills}

### SUM(), AVG(), ROUND()

The SUM() function is an aggregate function that calculates the total sum of a numeric column. The function is commonly used in conjunction with the GROUP BY clause to calculate sums for specific groups of data.

```{r gravity bookstore dataset erd png for section 2}
knitr::include_graphics("C:/Users/gam55/Downloads/gravity_bookstore_erd.png")

```

```{sql using the sum() function incorrectly}
SELECT SUM(street_name) as "No.different Street Names", SUM(city) as "No.different Cities"  FROM address;
```

As street_name and city are text columns, sum won't work properly on them. It's best to use COUNT(DISTINCT()).

```{sql using the sum() function}
SELECT COUNT(DISTINCT street_name) as "No. of Different Street Names", 
       COUNT(DISTINCT city) as "No. of Different Cities" 
FROM address;
```

```{r gravity bookstore dataset erd png for section 2 repeat}
knitr::include_graphics("C:/Users/gam55/Downloads/gravity_bookstore_erd.png")

```

```{sql using the sum() function correctly}

SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Order per Customer" DESC;

```

The AVG() function in SQL is an aggregate function that calculates the average value of a numeric column. It sums up all the values in the column and divides by the number of non-null values, providing the mean value.

```{sql using the sum() and avg() functions}

SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    AVG(ol.price) AS "Average Order Price per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Order per Customer" DESC;

```

The ROUND() function in SQL is used to round a numeric value to a specified number of decimal places. It takes two arguments: the number to be rounded and the number of decimal places to round to.

```{sql using the sum() and avg() and round() functions}

SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    ROUND(AVG(ol.price),2) AS "Average Order Price per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Order per Customer" DESC;

```

### Variance

The VARIANCE() function is used to calculate the statistical variance of a set of numeric values. The *variance* defines a measure of the spread dispersion within a set of data.

However, SQLite does not have a built-in VARIANCE() function.

To calculate variance in SQLite, one can use a combination of SQL functions.

-   *Calculating Sample Variance* -

The sample variance estimates the variance from a sample of the population. The formula is -

\[ \sigma^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1} \]

\[\sigma^2\] is the population variance

\[x_i\] represents each data point

\[\bar{x}\] is the sample mean

\[n - 1\] is the total number of data points in the population

Used when there's only a sample and need the population variance needs to be estimated. The denominator is \[n - 1\] . \[n - 1\] instead of \[n\] to correct the bias in the estimation of the population variance from a sample (Bessel's correction).

The SQL code -

SELECT SUM((value - avg_value) \* (value - avg_value)) / (COUNT(\*) - 1) AS sample_variance FROM ( SELECT value, AVG(value) AS avg_value FROM table_name ) AS subquery;

```{sql calculating sample variance of customers orders}

WITH OrderStats AS (
    SELECT 
        c.customer_id,
        SUM(ol.price) AS "Sum of Orders per Customer",
        AVG(ol.price) AS "Average Order Price per Customer",
        COUNT(ol.price) AS "Order Count",
        CONCAT(c.first_name, ' ', c.last_name) AS "Full Name"
    FROM 
        order_line ol
    INNER JOIN 
        cust_order co ON ol.order_id = co.order_id
    INNER JOIN 
        customer c ON co.customer_id = c.customer_id
    GROUP BY 
        c.customer_id, c.first_name, c.last_name
)
SELECT
    os."Sum of Orders per Customer",
    ROUND(os."Average Order Price per Customer", 2) AS "Average Order Price per Customer",
    os."Full Name",
    ROUND(SUM((ol.price - os."Average Order Price per Customer") * (ol.price - os."Average Order Price per Customer")) / (os."Order Count" - 1), 2) AS "Order Price Sample Variance"
FROM
    order_line ol
INNER JOIN
    cust_order co ON ol.order_id = co.order_id
INNER JOIN
    customer c ON co.customer_id = c.customer_id
INNER JOIN
    OrderStats os ON c.customer_id = os.customer_id
GROUP BY
    os.customer_id, os."Sum of Orders per Customer", os."Average Order Price per Customer", os."Full Name"
ORDER BY
    "Sum of Orders per Customer" DESC;

```

-   *Calculating Population Variance* -

The population variance measures the dispersion of all data points in a population from the population mean \[\mu\]. The formula is -

\[ \sigma^2 = \frac{\sum (x_i - \mu)^2}{N} \]

\[\sigma^2\] is the population variance

\[x_i\] represents each data point

\[\mu\] is the mean of the population

\[n\] is the total number of data points in the population

With large datasets, the difference between sample and population variance is minimal since the correction factor (n - 1) vs. (n) has a smaller impact as the sample size increases.

The SQL code -

SELECT AVG((value - avg_value) \* (value - avg_value)) AS population_variance FROM ( SELECT value, AVG(value) AS avg_value FROM table_name ) AS subquery;

```{sql calculating population variance of customers orders}

WITH OrderStats AS (
    SELECT 
        c.customer_id,
        SUM(ol.price) AS "Sum of Orders per Customer",
        AVG(ol.price) AS "Average Order Price per Customer",
        COUNT(ol.price) AS "Order Count",
        CONCAT(c.first_name, ' ', c.last_name) AS "Full Name"
    FROM 
        order_line ol
    INNER JOIN 
        cust_order co ON ol.order_id = co.order_id
    INNER JOIN 
        customer c ON co.customer_id = c.customer_id
    GROUP BY 
        c.customer_id, c.first_name, c.last_name
)
SELECT
    os."Sum of Orders per Customer",
    ROUND(os."Average Order Price per Customer", 2) AS "Average Order Price per Customer",
    os."Full Name",
    ROUND(SUM((ol.price - os."Average Order Price per Customer") * (ol.price - os."Average Order Price per Customer")) / os."Order Count", 2) AS "Order Price Population Variance"
FROM
    order_line ol
INNER JOIN
    cust_order co ON ol.order_id = co.order_id
INNER JOIN
    customer c ON co.customer_id = c.customer_id
INNER JOIN
    OrderStats os ON c.customer_id = os.customer_id
GROUP BY
    os.customer_id, os."Sum of Orders per Customer", os."Average Order Price per Customer", os."Full Name"
ORDER BY
    "Sum of Orders per Customer" DESC;

```

### Standard Deviation

Standard deviation measures the dispersion of a dataset relative to its mean, indicating how spread out the data points are. A low standard deviation means the data points are close to the mean, while a high standard deviation indicates they are more spread out.

SQLite does not have a built-in STDDEV() or STDEV() function for calculating standard deviation.

These are the steps to calculate standard deviation in SQLite:

1.  Calculate the mean of the dataset.

2.  Compute Squared Differences calculate the squared difference of each value from the mean.

3.  Aggregate and Calculate - Sum up the squared differences, divide by the count of values (for population standard deviation) or by (n - 1) (for sample standard deviation), and take the square root of the result.

The population standard deviation ((\sigma)) is calculated using the formula:

\[ \sigma = \sqrt{\frac{\sum_{i=1}^{N} (x_i - \mu)^2}{N}} \]

where: - (\sigma) is the population standard deviation, - (x_i) represents each data point, - (\mu) is the mean of the population, - (N) is the total number of data points in the population.

The SQL code -

SELECT SQRT(AVG((value - avg_value) \* (value - avg_value))) AS population_stddev FROM ( SELECT value, AVG(value) OVER () AS avg_value FROM table_name ) AS subquery;

```{sql calculating population standard deviation}
WITH OrderStats AS (
    SELECT 
        c.customer_id,
        SUM(ol.price) AS "Sum of Orders per Customer",
        AVG(ol.price) AS "Average Order Price per Customer",
        COUNT(ol.price) AS "Order Count",
        CONCAT(c.first_name, ' ', c.last_name) AS "Full Name"
    FROM 
        order_line ol
    INNER JOIN 
        cust_order co ON ol.order_id = co.order_id
    INNER JOIN 
        customer c ON co.customer_id = c.customer_id
    GROUP BY 
        c.customer_id, c.first_name, c.last_name
)
SELECT
    os."Sum of Orders per Customer",
    ROUND(os."Average Order Price per Customer", 2) AS "Average Order Price per Customer",
    os."Full Name",
    ROUND(SUM((ol.price - os."Average Order Price per Customer") * (ol.price - os."Average Order Price per Customer")) / os."Order Count", 2) AS "Order Price Population Variance",
    ROUND(SQRT(SUM((ol.price - os."Average Order Price per Customer") * (ol.price - os."Average Order Price per Customer")) / os."Order Count"), 2) AS "Order Price Standard Deviation"
FROM
    order_line ol
INNER JOIN
    cust_order co ON ol.order_id = co.order_id
INNER JOIN
    customer c ON co.customer_id = c.customer_id
INNER JOIN
    OrderStats os ON c.customer_id = os.customer_id
GROUP BY
    os.customer_id, os."Sum of Orders per Customer", os."Average Order Price per Customer", os."Full Name"
ORDER BY
    "Sum of Orders per Customer" DESC;

```

The sample standard deviation ((s)) is calculated using the formula:

\[ s = \sqrt{\frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n - 1}} \]

where: - (s) is the sample standard deviation, - (x_i) represents each data point in the sample, - (\bar{x}) is the sample mean, - (n) is the number of data points in the sample.

The SQL code -

SELECT SQRT(SUM((value - avg_value) \* (value - avg_value)) / (COUNT(\*) - 1)) AS sample_stddev FROM ( SELECT value, AVG(value) OVER () AS avg_value FROM table_name ) AS subquery;

```{sql calculating sample variance and standard deviation}

WITH SampledCustomers AS (
    SELECT 
        c.customer_id,
        c.first_name,
        c.last_name
    FROM 
        customer c
    ORDER BY 
        RANDOM()
    LIMIT 50
),
OrderStats AS (
    SELECT 
        c.customer_id,
        SUM(ol.price) AS "Sum of Orders per Customer",
        AVG(ol.price) AS "Average Order Price per Customer",
        COUNT(ol.price) AS "Order Count",
        CONCAT(c.first_name, ' ', c.last_name) AS "Full Name"
    FROM 
        order_line ol
    INNER JOIN 
        cust_order co ON ol.order_id = co.order_id
    INNER JOIN 
        SampledCustomers c ON co.customer_id = c.customer_id
    GROUP BY 
        c.customer_id, c.first_name, c.last_name
)
SELECT
    os."Sum of Orders per Customer",
    ROUND(os."Average Order Price per Customer", 2) AS "Average Order Price per Customer",
    os."Full Name",
    ROUND(SUM((ol.price - os."Average Order Price per Customer") * (ol.price - os."Average Order Price per Customer")) / (os."Order Count" - 1), 2) AS "Order Price Sample Variance",
    ROUND(SQRT(SUM((ol.price - os."Average Order Price per Customer") * (ol.price - os."Average Order Price per Customer")) / (os."Order Count" - 1)), 2) AS "Order Price Sample Standard Deviation"
FROM
    order_line ol
INNER JOIN
    cust_order co ON ol.order_id = co.order_id
INNER JOIN
    customer c ON co.customer_id = c.customer_id
INNER JOIN
    OrderStats os ON c.customer_id = os.customer_id
GROUP BY
    os.customer_id, os."Sum of Orders per Customer", os."Average Order Price per Customer", os."Full Name"
ORDER BY
    "Sum of Orders per Customer" DESC;

```

------------------------------------------------------------------------

## 3 - WITH() function {.tabset .tabset-fade .tabset-pills}

WITH(), also known as Common Table Expressions (CTEs), allows for improved readability and reusability of SQL queries. It's particularly useful for breaking down complex queries into simpler, more manageable parts by creating temporary result sets that can be referenced within the main query.

WITH cte_name AS ( -- CTE Query SELECT ... ) SELECT ... FROM cte_name

[**Key Differences**]{.ul}

1.  **Structure and Readability -**

*Subqueries* - Can be less readable, especially when nested.

*WITH()* - Provide a clearer, more structured approach by defining temporary tables with meaningful names.

2.  **Reusability** -

*Subqueries -* Generally not reusable; you need to repeat the subquery if it's used in multiple places.

*WITH()* - Reusable within the main query, reducing redundancy and improving maintainability.

3.  **Debugging and Maintenance** -

*Subqueries -* Harder to debug and maintain due to their nested nature.

*WITH() -* Easier to debug and maintain due to their clear, modular structure.

**When using WITH()**

```{sql getting total amount spent and average order amount using the with clause}

-- Step 1: Calculate the total amount spent by each customer
WITH CustomerSpending AS (
    SELECT 
        co.customer_id,
        CONCAT(c.first_name, ' ', c.last_name) AS full_name,
        SUM(ol.price) AS total_spent
    FROM 
        cust_order co
    INNER JOIN 
        order_line ol ON co.order_id = ol.order_id
    INNER JOIN 
        customer c ON co.customer_id = c.customer_id
    GROUP BY 
        co.customer_id, full_name
)

-- Step 2: Select the top 5 customers and join with book details
SELECT
    b.title,
    ol.price,
    cs.full_name,
    cs.total_spent
FROM 
    CustomerSpending cs
INNER JOIN 
    cust_order co ON cs.customer_id = co.customer_id
INNER JOIN 
    order_line ol ON co.order_id = ol.order_id
INNER JOIN 
    book b ON ol.book_id = b.book_id
WHERE 
    cs.customer_id IN (
        SELECT customer_id 
        FROM CustomerSpending 
        ORDER BY total_spent DESC 
        LIMIT 5
    )
ORDER BY 
    cs.total_spent DESC;
```

The part with the WITH inner query -

-   This CTE calculates the total amount spent on each order for every customer.

-   It joins the cust_order,order_line, and customers tables and groups the data by customer ID and full name to compute the total order amount.

The rest, the outer query -

-   The main query selects from the CustomerSpending CTE.

-   It also gets the book title and price from the book and order line tables respectively, by INNER JOINs. 
-   A WHERE clause specifies the results should only contains the top 5 spending customers in CustomerSpending. 

- The results are ordered by the top spenders, descending. 


------------------------------------------------------------------------

## 4 - Further Data Manipulation in SQL {.tabset .tabset-fade .tabset-pills}

### the 'like' operator

```{r gravity bookstore dataset erd png for section 4, message=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/gam55/Downloads/gravity_bookstore_erd.png")

```

The `LIKE` operator is used for pattern matching within text fields. It allows the use of `%` to represent zero or more characters and `_` to represent a single character. For example, the query `SELECT * FROM customers WHERE name LIKE '%enko';` will return all rows where the `name` column ends with "enko".

Getting all surnames starting with 'Mac' -

```{sql finding all customers whose surname starts with Mac}
select * from customer where last_name like 'Mac%'
```

Getting all surnames starting with 'Mc' -

```{sql finding all customers whose surname starts with Mc}
select * from customer where last_name like 'Mc%'
```

Getting all surnames ending with 'vich' -

```{sql finding all customers whose surname ends in vich}
select * from customer where last_name like '%vich'
```

Getting all surnames ending with 'enko' -

```{sql finding all customers whose surname ends in enko}
select * from customer where last_name like '%enko'
```

Getting all surnames starting or ending with 'man' (lower or upper case) -

```{sql finding all customers whose surname is like man}
select * from customer where last_name like '%man%'
```

### SIMILAR TO

Making a new column specifically based on the like condition -

```{sql getting Ukrainian like names}

SELECT 
    last_name as "Customer Surname", 
    CASE 
        WHEN last_name LIKE '%enko' 
            OR last_name LIKE '%vich' 
            OR last_name LIKE '%vych' 
            OR last_name LIKE '%chuk' 
            OR last_name LIKE '%chyk' 
            OR last_name LIKE '%ski' 
            OR last_name LIKE '%sky' 
            OR last_name LIKE '%uk' 
            OR last_name LIKE '%ko' 
            OR last_name LIKE '%yshyn' 
            OR last_name LIKE '%iv' THEN 'Yes' 
        ELSE 'No' 
    END AS 'Potentially Ukrainian Surname?' 
FROM customer 
WHERE last_name LIKE '%enko' 
    OR last_name LIKE '%vich' 
    OR last_name LIKE '%vych' 
    OR last_name LIKE '%chuk' 
    OR last_name LIKE '%chyk' 
    OR last_name LIKE '%ski' 
    OR last_name LIKE '%sky' 
    OR last_name LIKE '%uk' 
    OR last_name LIKE '%ko' 
    OR last_name LIKE '%yshyn' 
    OR last_name LIKE '%iv';


```

Unfortunately, SQLite that's being used here does not support the command *'similar to'* that could be used in PostGreSQL.

If PostGreSQL was being used, the above query could be shortened a lot -

SELECT last_name, CASE WHEN last_name SIMILAR TO '%(enko\|vich\|vych\|chuk\|chyk\|ski\|sky\|uk\|ko\|yshyn\|iv)' THEN 'YES' ELSE 'NO' END AS "Ukrainian Surname" FROM customer WHERE last_name SIMILAR TO '%(enko\|vich\|vych\|chuk\|chyk\|ski\|sky\|uk\|ko\|yshyn\|iv)';

### SOUNDEX

```{r gravity bookstore dataset erd png for section 4 part2, message=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/gam55/Downloads/gravity_bookstore_erd.png")

```

SOUNDEX is a phonetic algorithm that indexes words by their sound when pronounced in English. This can be useful for matching words that sound similar but are spelled differently. SQLite has this function.

```{sql testing soundex on George}

SELECT SOUNDEX('George');

```

```{sql finding last names that sound like Smyth}

SELECT last_name AS 'Surnames' 
FROM customer
WHERE SOUNDEX(last_name) = SOUNDEX('Smyth');


```

```{sql testing soundex with postgresql}

select soundex('Postgres'), soundex('Postgresss'), ('Postgres' = 'Postgresss'),
soundex('Postgres') = soundex('Postgresss')
```

A SOUNDEX code consists of a letter followed by three digits, representing the phonetic pattern of the word. Here's how it is constructed:

-   First Letter: The first letter of the word is kept as the first letter of the SOUNDEX code.

-   Digits: The remaining letters are converted to digits based on their phonetic sound:

B, F, P, V → 1

C, G, J, K, Q, S, X, Z → 2

D, T → 3

L → 4

M, N → 5

R → 6

-   Similar Sounds: Adjacent letters that represent the same sound are collapsed into a single digit.

-   Vowels and Certain Letters: A, E, I, O, U, H, W, and Y are ignored unless they are the first letter.

-   Truncation/Zero Padding: The code is truncated to four characters if necessary, or zero-padded to ensure it is four characters long.

-   For example, the SOUNDEX code "P232" is generated from the word "Postgres" as follows:

    'P' is the first letter.

    'o' is ignored.

    's' maps to 2.

    't' maps to 3.

    'g' maps to 2.

    Remaining letters ('r', 'e', 's') are either ignored or do not change the pattern as the code is already four characters long.

Thus, "Postgres" becomes "P232".

```{sql Difference between the strings Postgres and Postgresss}

select difference ('Postgres', 'Postgresss') as "Difference between the strings Postgres and Postgresss"

```

The DIFFERENCE() function in SQL compares the SOUNDEX values of two strings and returns an integer value between 0 and 4, indicating the degree of similarity between the two strings. A result of 4 means the strings sound very similar, while a result of 0 means they sound very different. This function is particularly useful for fuzzy matching in text searches.

The levenshtein() function calculates the Levenshtein distance between two strings, which is the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one string into the other. It is commonly used to measure the similarity between two strings, with a lower distance indicating greater similarity.

SQLite doesn't have it unfortunately!


------------------------------------------------------------------------

## 5 - Window Functions {.tabset .tabset-fade .tabset-pills}

```{r gravity bookstore dataset erd png for section 6, message=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/gam55/Downloads/gravity_bookstore_erd.png")

```

Window functions in SQL perform calculations across a set of table rows that are somehow related to the current row. Unlike aggregate functions, which return a single value for a group of rows, window functions can return multiple rows for each row in the query, preserving the row's identity. These functions are often used for running totals, moving averages, and other cumulative calculations.

### ROW_NUMBER()

ROW_NUMBER() - Assigns a unique sequential integer to rows within a partition of a result set.

Assigns a unique sequential integer to each row, ordered by "Sum of Orders per Customer" in descending order, useful for ranking albeit with ties (there can't be 2 third placed rows for example).

```{sql generating the row number of sum or orders per customer}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
    ROW_NUMBER() OVER (ORDER BY SUM(ol.price) DESC) AS "Row Number"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC;
```

### RANK()

Assigns a rank to each row, with gaps in the ranking sequence for ties.

Assigns a rank to each customer based on their "Sum of Orders per Customer", allowing for ties where customers with the same sum receive the same rank. No 89th position just two 88 positions.

```{sql getting the rank of sum or orders per customer from positions 80 to 90}
WITH RankedCustomers AS (
    SELECT 
        SUM(ol.price) AS "Sum of Orders per Customer",
        CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
        RANK() OVER (ORDER BY SUM(ol.price) DESC) AS "Rank"
    FROM 
        order_line ol
    INNER JOIN 
        cust_order co ON ol.order_id = co.order_id
    INNER JOIN 
        customer c ON co.customer_id = c.customer_id
    GROUP BY 
        c.first_name, c.last_name
)
SELECT *
FROM RankedCustomers
WHERE "Rank" BETWEEN 85 AND 95
ORDER BY "Rank";


```

### DENSE_RANK()

DENSE_RANK() does not leave gaps and provides consecutive ranking numbers regardless of the number of ties whereas RANK() leaves gaps in the ranking sequence if there are ties. An 89th position as well as two 88 positions.

```{sql using dense rank on orders per customer}

WITH RankedCustomers AS (
    SELECT 
        SUM(ol.price) AS "Sum of Orders per Customer",
        CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
        DENSE_RANK() OVER (ORDER BY SUM(ol.price) DESC) AS "Dense Rank"
    FROM 
        order_line ol
    INNER JOIN 
        cust_order co ON ol.order_id = co.order_id
    INNER JOIN 
        customer c ON co.customer_id = c.customer_id
    GROUP BY 
        c.first_name, c.last_name
)
SELECT *
FROM RankedCustomers
WHERE "Dense Rank" BETWEEN 85 AND 95
ORDER BY "Dense Rank";


```

### NTILE()

Distributes the rows into a specified number of buckets (here, deciles), providing a way to understand distribution across different segments.

```{sql distributing rows into specific deciles using NTILE}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
NTILE(10) OVER (ORDER BY SUM(ol.price) DESC) AS "Decile"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC;
```

### LEAD()

Provides access to the next value in the query result, useful for comparing each customer's sum with the next customer's sum.

```{sql demonstrating the lead function on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
LEAD(SUM(ol.price)) OVER (ORDER BY SUM(ol.price) DESC) AS "Next Customer's Sum"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC
LIMIT 5;
```

### LAG()

The converse of LEAD(). LAG() provides access to the previous value in the query result, useful for comparing each customer's sum with the next customer's sum.

```{sql demonstrating the lag function on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
LAG(SUM(ol.price)) OVER (ORDER BY SUM(ol.price) DESC) AS "Previous Customer's Sum"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC
LIMIT 5;
```

### FIRST_VALUE()

Returns the sum of orders for the top customer in the ordered list as a seperate column, giving a reference point for the highest sum of orders.

```{sql demonstrating the first_value function on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
FIRST_VALUE(SUM(ol.price)) OVER (ORDER BY SUM(ol.price) DESC) AS "First Customer Sum"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC
LIMIT 5;
```

### LAST_VALUE()

Returns the sum of orders for the bottom customer in the ordered list as a seperate column, giving a reference point for the lowest sum of orders.

```{sql demonstrating the last_value function on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
LAST_VALUE(SUM(ol.price)) OVER (ORDER BY SUM(ol.price) DESC) AS "Last Customer Sum"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" ASC
LIMIT 5;
```

### SUM(),AVG(),MAX() or MIN() with OVER()

SUM() with OVER() calculates the total sum of all orders across all customers, providing a grand total within the context of each row.

```{sql demonstrating the usage of sum in conjuction with over on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
SUM(SUM(ol.price)) OVER () AS "Total Sum of All Customers"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC
LIMIT 5;
```

AVG() with OVER() calculates the total sum of all orders across all customers, providing a grand total within the context of each row.

```{sql demonstrating the usage of avg in conjuction with over on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
AVG(SUM(ol.price)) OVER () AS "Average Order Sum"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC
LIMIT 5;
```

MAX() with OVER() returns the maximum sum of orders found in the dataset, providing a reference for the highest order sum among all customers.

```{sql demonstrating the usage of max in conjuction with over on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
MAX(SUM(ol.price)) OVER () AS "Max. Sum of Orders"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC
LIMIT 5;
```

MIN() with OVER() returns the minimum sum of orders found in the dataset, providing a reference for the highest order sum among all customers.

```{sql demonstrating the usage of min in conjuction with over on customer orders}
SELECT 
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
MIN(SUM(ol.price)) OVER () AS "Min. Sum of Orders"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
GROUP BY 
    c.first_name, c.last_name
ORDER BY 
    "Sum of Orders per Customer" DESC
LIMIT 5;
```

### PARTITION BY(), CUME_DIST() and WIDTH_BUCKET

A partition is a subset of rows in the result set. When you use a window function with the PARTITION BY clause, the window function is applied to each partition separately. This is useful for performing calculations within each group of rows.

```{sql utilising partition by}

SELECT 
    a.city,
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
    RANK() OVER (PARTITION BY a.city ORDER BY SUM(ol.price) DESC) AS "Rank"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
INNER JOIN
    address a ON co.dest_address_id = a.address_id
GROUP BY 
    a.city, c.first_name, c.last_name
ORDER BY 
    a.city, "Rank";



```

CUME_DIST() calculates the cumulative distribution of a value within a partition. It returns the relative position of a value within the partition as a number between 0 and 1. It shows the proportion of rows that have a value less than or equal to the current row's value.

```{sql utilising cume dist}
SELECT 
    a.city,
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
    CUME_DIST() OVER (PARTITION BY a.city ORDER BY SUM(ol.price) DESC) AS "Cumulative Distribution"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
INNER JOIN
    address a ON co.dest_address_id = a.address_id
WHERE
    a.city = 'A Yun Pa'  -- Filter for specific city here
GROUP BY 
    a.city, c.first_name, c.last_name
ORDER BY 
    a.city, "Sum of Orders per Customer" DESC;

```

The above result means 100% of customers have a sum of orders less than or equal to Cristen's, 2/3 less than or equal to Mariettes's, and 1/3% less than or equal to Joelie's.

The WIDTH_BUCKET function divides a continuous range of values into a specified number of equal-width buckets, returning the bucket number for each value. It is commonly used to categorize numeric data into intervals for analysis.

For example -

Below one can see that the salary column has been divided 10 times, from the values 0 to 150,000.

```{r gravity bookstore dataset erd png for section 6 part2, message=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/gam55/Downloads/width_bucket_screenshot.png")

```

SQLite does not support the WIDTH_BUCKET function directly but it can be simulated using a series of CASE statements.

```{sql using case statements instead of width bucket }
SELECT 
    a.city,
    SUM(ol.price) AS "Sum of Orders per Customer",
    CONCAT(c.first_name, ' ', c.last_name) AS "Full Name",
    CASE 
        WHEN SUM(ol.price) < 100 THEN 3
        WHEN SUM(ol.price) BETWEEN 100 AND 200 THEN 2
        WHEN SUM(ol.price) BETWEEN 201 AND 300 THEN 1
        ELSE 4
    END AS "Bucket"
FROM 
    order_line ol
INNER JOIN 
    cust_order co ON ol.order_id = co.order_id
INNER JOIN 
    customer c ON co.customer_id = c.customer_id
INNER JOIN
    address a ON co.dest_address_id = a.address_id
GROUP BY 
    a.city, c.first_name, c.last_name
ORDER BY 
    a.city, "Sum of Orders per Customer" DESC;

```

### WITH RECURSIVE

SQLite supports the WITH RECURSIVE clause, which allows you to write recursive CTEs. This feature is useful for querying hierarchical or recursive data, such as workplace hierarchy or family trees.

Some of the explanations below have been lifted from <https://learnsql.com/blog/sql-recursive-cte/>

[**Recap on 'common table expressions', CTEs**]{.ul}

"The CTE (common table expression), also known as the `WITH` clause, is an SQL feature that returns a temporary data set that can be used by another query. As it's a temporary result, it's not stored anywhere, but it still can be referenced like you would reference any other table."

"A recursive CTE references itself. It returns the result subset, then it repeatedly (recursively) references itself, and stops when it returns all the results."

The general syntax of a non-recursive CTE -

`WITH` `cte_name AS` `(cte_query_definition)`

 

`SELECT` `*`

`FROM`   `cte_name;`

"The first part of the syntax is the CTE. It begins with the keyword `WITH`. Then you give your CTE a name. After you follow that by the `AS` keyword, you can define CTE in the parentheses."

"The second part of the syntax is a simple `SELECT` statement. It is written immediately after the recursive CTE, without any commas, semicolons, or similar marks. The CTE is used in another query just like any other table. This is exactly what the `SELECT` statement does."

[**Recursive CTEs**]{.ul}

A recursive CTE references itself. It returns the result subset, then it repeatedly (recursively) references itself, and stops when it returns all the results.

The syntax for a recursive CTE is not too different from that of a non-recursive CTE -

`WITH` `RECURSIVE cte_name AS` `(`

`cte_query_definition (the anchor member)`

 

`UNION` `ALL`

 

`cte_query_definition (the recursive member)`

`)`

 

 

`SELECT` `*`

`FROM`   `cte_name;`

"Again, at the beginning of your CTE is the `WITH` clause. However, if you want your CTE to be recursive, then after `WITH` you write the `RECURSIVE` keyword. Then it's business as usual: `AS` is followed by the parentheses with the CTE query definition. This first query definition is called **the anchor member**."

"To connect the anchor member with the **recursive member**, you need to use the `UNION` or `UNION ALL` command. The recursive member is, obviously, the recursive part of CTE that will reference the CTE itself."

[***Finding Hierarchy in a Workplace*** **Example**]{.ul}

The 'Gravity Bookstore' used so far in this document doesn't have any kind of hierarchical data some needs to be created -

```{sql creating an employee table}
CREATE TABLE employee (
    employee_id INTEGER PRIMARY KEY,
    name TEXT,
    position TEXT,
    manager_id INTEGER
);
```

```{sql insert into employees table}
INSERT INTO employee (employee_id, name, position, manager_id) VALUES
(1, 'Alice', 'CEO', NULL),        -- Top-level management
(2, 'Bob', 'VP of Sales', 1),
(3, 'Carol', 'VP of Engineering', 1),
(4, 'Dave', 'Sales Manager', 2),
(5, 'Eve', 'Sales Executive', 4),
(6, 'Frank', 'Sales Executive', 4),
(7, 'Grace', 'Engineering Manager', 3),
(8, 'Heidi', 'Senior Engineer', 7),
(9, 'Ivan', 'Junior Engineer', 7),
(10, 'Judy', 'CTO', 1),
(11, 'Mallory', 'Sales Associate', 5),
(12, 'Oscar', 'Sales Associate', 5),
(13, 'Peggy', 'Engineering Intern', 9),
(14, 'Sybil', 'Product Manager', 3),
(15, 'Trent', 'DevOps Engineer', 7),
(16, 'Victor', 'Lead Architect', 10),
(17, 'Walter', 'Data Scientist', 16),
(18, 'Xavier', 'ML Engineer', 17),
(19, 'Yvonne', 'UX Designer', 14),
(20, 'Zara', 'Graphic Designer', 19);
```

```{sql viewing employee table}

select * from employee
```

```{sql using a with recursive statement to find out the hierarchy of data}
WITH RECURSIVE company_hierarchy AS (
  SELECT 
    employee_id,
    name,
    position,
    manager_id,
    0 AS hierarchy_level
  FROM 
    employee
  WHERE 
    manager_id IS NULL  
  
  UNION ALL
   
  SELECT 
    e.employee_id,
    e.name,
    e.position,
    e.manager_id,
    ch.hierarchy_level + 1
  FROM 
    employee e, 
    company_hierarchy ch
  WHERE 
    e.manager_id = ch.employee_id
)
 
SELECT 
  ch.name AS "Employee name",
  e.name AS "Boss name",
  ch.position AS "Employee Position",
  e.position AS "Boss Position",
  ch.hierarchy_level AS "Hierarchy Level"
FROM 
  company_hierarchy ch
LEFT JOIN 
  employee e ON ch.manager_id = e.employee_id
ORDER BY 
  ch.hierarchy_level, 
  ch.manager_id;


```

The above is a recursive query, so it starts with `WITH RECURSIVE`. The name of the CTE is `company_hierarchy`. After `AS`, the CTE definition is in the parentheses.

The first `SELECT` statement, ***the anchoring statement***, selects all the **`employee`** table columns where the column `manager_id` is `NULL`. In short, it will select Alice, because only she has a `NULL` value in that column - starting the recursion from the top of the organizational structure. There's also a column `hierarchy_level` with the value of 0. That means the head of the company's level is 0 -- they're on top of the hierarchy.

`UNION ALL` is used to connect this SELECT statement with the second one, ***the recursive member***. In the recursive member, all the columns from the table **`employees`** ares selected and the CTE `company_hierarchy` where the column `boss_id` is equal to the column `id`. Notice the part `hierarchy_level + 1`.This means that with every recursion, the CTE will add 1 to the previous hierarchy level, and it will do that until it reaches the end of the hierarchy. Also note that the CTE is treated as any other table. To finish defining the CTE, the brackets are closed.

Finally, there's a third `SELECT` statement, outside of the CTE. It selects the columns that will show employees, their bosses' names, and the hierarchy level. Data is taken from the CTE and the table **`employees`**. The CTE and **`employees`** table are joined with a `LEFT JOIN`, since we want all the data from the CTE -- including Alice, who has the `NULL` value in the column `boss_id`.

In a very simplistic way -

***"Recursive CTEs are used to handle and query data that refers to itself, like finding all employees who report to a manager in a company hierarchy."***

